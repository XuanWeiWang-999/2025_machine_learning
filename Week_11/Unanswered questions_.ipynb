{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "315654f0",
   "metadata": {},
   "source": [
    "# Unanswered Question - Week 1-10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd6b239",
   "metadata": {},
   "source": [
    "## Week 1  \n",
    "### Questions\n",
    "Noticed that the update formula for **gradient descent** sometimes includes different coefficients, such as:\n",
    "\n",
    "$$\n",
    "\\theta^{n+1} = \\theta^n - \\alpha \\nabla L(\\theta)\n",
    "$$\n",
    "vs.\n",
    "$$\n",
    "\\theta^{n+1} = \\theta^n + \\frac{2\\alpha}{m} \\sum (y^{(i)} - h(x^{(i)})) \\nabla_\\theta h\n",
    "$$\n",
    "\n",
    "這邊的問題是：\n",
    "* 為甚麼公式看起來有些不一樣? 是因為只差在$\\frac{1}{2}$的factor而已嗎?\n",
    "* 如果一些常數可以被$\\alpha$自然吸收掉，那是不是就意味著那些常數本來就不重要?反正只要選一個\"好的\"$\\alpha$就好?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae21965e",
   "metadata": {},
   "source": [
    "### Answer\n",
    "#### 1. 為什麼兩個公式看起來不一樣？\n",
    "因為損失函數的定義不同，特別是 **有沒有放 1/2**。  \n",
    "若沒有放 1/2，梯度會多一個 2；若放了 1/2，這個 2 會被抵消，所以更新式看起來不同。\n",
    "\n",
    "\n",
    "#### 2. 這些常數重要嗎？\n",
    "確實在實作當中不重要，因為它們都可以被 **學習率 α 吸收**。  \n",
    "真正影響收斂的是 α 的選擇，而不是前面的 2 或 1/2。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3c92ca",
   "metadata": {},
   "source": [
    "### References\n",
    "* Ian Goodfellow, Yoshua Bengio,  Aaron Courville, *Deep Learning*,chapter 4.3.  \n",
    "* beihangzxm123, *Machine Learning - Andrew Ng on Coursera (Week 2)*, 2016.03.28, [網路資料](https://blog.csdn.net/qq_26898461/article/details/50995810)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633dddfd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2\n",
    "### Question\n",
    "MLE maximizes training log-likelihood. With high-capacity models or small/noisy data, it fits idiosyncrasies → poor generalization and over-confident probabilities.  \n",
    "Is there any good method to solve this kind of overfitting problem?\n",
    "\n",
    "「MLE 會最大化訓練資料的對數似然。在模型容量很大、或資料量太小／噪音太多時，它會去擬合資料中的偶然特性（idiosyncrasies），導致泛化能力變差、預測機率過度自信。\n",
    "那有沒有什麼好方法可以解決這類過擬合的問題呢？」"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7615c2",
   "metadata": {},
   "source": [
    "#### 如何解決 MLE 過擬合（overfitting）問題？\n",
    "\n",
    "1. **Regularization（正則化）**  \n",
    "   在 log-likelihood 上加入 penalty，例如 L2（weight decay）、L1。  \n",
    "   → 控制模型複雜度，阻止參數無限放大。\n",
    "\n",
    "2. **Bayesian Methods（貝葉斯方法）**  \n",
    "   MLE 換成 MAP，加 prior；或使用 variational inference。  \n",
    "   → 讓模型不會出現過度自信的 posterior。\n",
    "\n",
    "3. **Early Stopping（提前停止）**  \n",
    "   觀察 validation loss，一旦開始上升就停止訓練。\n",
    "\n",
    "4. **Dropout / Noise Injection（隱藏單元丟棄、加入噪音）**  \n",
    "   常用於 deep models，可視為 implicit regularization。\n",
    "\n",
    "5. **Data Augmentation（資料增強）**  \n",
    "   對影像、語音或 NLP 特別有效，提高泛化。\n",
    "\n",
    "6. **Ensemble（集成方法）**  \n",
    "   Bagging、Random Forest、Boosting、Deep Ensembles。  \n",
    "   → 能有效降低過度自信的預測。\n",
    "\n",
    "7. **Label Smoothing（標籤平滑）**  \n",
    "   特別在分類模型能降低過度自信的 softmax 輸出。\n",
    "\n",
    "8. **Temperature Scaling / Calibration（機率校準）**  \n",
    "   減少 MLE 產生的 over-confident probabilities。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2766b56d",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1. Christopher Bishop, *Pattern Recognition and Machine Learning*, Chapter 1.5 & 3.  \n",
    "   — 討論 MLE、MAP 與 overfitting 的關係。\n",
    "\n",
    "2. Ian Goodfellow, Yoshua Bengio, Aaron Courville,  \n",
    "   *Deep Learning*, Chapter 5 & 7.  \n",
    "   — 詳述 regularization 與各種防止過擬合的方法。\n",
    "\n",
    "3. Andrew Ng, CS229 Lecture Notes (Supervised Learning).  \n",
    "   — 清楚說明為何 MLE 會過擬合以及 regularization 的效果。\n",
    "\n",
    "4. \"Dropout: A Simple Way to Prevent Neural Networks from Overfitting\",  \n",
    "   Srivastava et al., JMLR 2014.\n",
    "\n",
    "5. \"Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles\",  \n",
    "   Lakshminarayanan et al., NIPS 2017.  \n",
    "   — 深度模型 over-confidence 的經典解法。\n",
    "\n",
    "6. \"On Calibration of Modern Neural Networks\",  \n",
    "   Guo et al., ICML 2017.  \n",
    "   — 提出 temperature scaling。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b4cd86",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c186d067",
   "metadata": {},
   "source": [
    "## Week 3\n",
    "### Question\n",
    "In the reference paper, in both Lemma 3.1 and Lemma 3.2, the construction shows that shallow tanh networks can approximate monomials with arbitrary accuracy. However, the required weights often grow rapidly as the error tolerance $\\varepsilon \\to 0$ or as the polynomial degree $s$ increases.\n",
    "\n",
    "What are the implications of such large weights in practice? For instance, could excessively large weights lead to numerical instability, gradient explosion or vanishing during training, or poor generalization?\n",
    "\n",
    "How might one balance theoretical approximation guarantees with practical considerations in optimization?\n",
    "\n",
    "在參考的論文中，Lemma 3.1 與 Lemma 3.2 的構造顯示：淺層的 tanh 網路可以以任意精度逼近單項式。然而，當誤差容許度 \n",
    "$ \\varepsilon \\to 0 $或多項式階數 $s$ 增加時，所需的權重會快速變大。\n",
    "\n",
    "這樣巨大的權重在實務上會造成什麼影響？例如，過大的權重是否可能導致數值不穩定、gradient爆炸或不見、或generalization的能力下降？\n",
    "\n",
    "又該如何在「理論上的函數逼近保證」與「實際可行的最佳化與訓練」之間取得平衡？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3485d4b0",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "#### 1. 巨大權重的影響\n",
    "##### 1.1 數值不穩定（Numerical Instability）\n",
    "- 權重越大，網路輸出越容易超出硬體float的範圍 ，造成 overflow。\n",
    "- 在 tanh 或 sigmoid 中，大input會使 activations 飽和，導致梯度極小。\n",
    "\n",
    "##### 1.2 梯度爆炸與梯度消失（Gradient Explosion / Vanishing）\n",
    "- 大權重會放大誤差與gradient，造成訓練不穩定。  \n",
    "- 飽和值區會讓梯度消失，導致網路無法更新。\n",
    "\n",
    "##### 1.3 泛化能力變差（Poor Generalization）\n",
    "- 巨大權重常意味網路對數據分布太敏感，容易 overfitting。  \n",
    "- 實務上，平滑、較小的權重通常帶來更好的泛化表現。\n",
    "\n",
    "##### 1.4 最佳化困難\n",
    "- Loss landscape 會變得陡峭或不平滑，讓 SGD / Adam 更難找到良好收斂點。\n",
    "\n",
    "#### 2. 如何在理論與實務之間取得平衡?\n",
    "##### 2.1 加入 Regularization\n",
    "- **L2 regularization（weight decay）** 可直接限制權重大小。  \n",
    "- **L1** 也能強制 sparsity 並間接減少極端權重。\n",
    "\n",
    "公式示意：  \n",
    "\\[\n",
    "\\min_\\theta L(\\theta) + \\lambda \\|\\theta\\|_2^2\n",
    "\\]\n",
    "\n",
    "##### 2.2 使用更適合逼近的 Activation（如 ReLU, GELU）\n",
    "某些 activation（如 tanh）在輸入大時容易飽和，  \n",
    "若改用 ReLU 類激活，可降低對巨大權重的需求。\n",
    "\n",
    "文獻中也指出 ReLU 的逼近效率通常比 tanh 更有利。\n",
    "\n",
    "##### 2.3 使用更深的模型（Depth > Width）\n",
    "深度網路的理論（如 Telgarsky、Eldan-Shamir）指出：  \n",
    "**深度能以較少權重、更平緩的參數達到同等逼近能力。**\n",
    "\n",
    "※ 深度減少巨大權重的必要性  \n",
    "※ 深度增加 representation efficiency\n",
    "\n",
    "##### 2.4 正則化初始化與 Normalization\n",
    "- Xavier / Kaiming initialization 限制初始權重範圍  \n",
    "- BatchNorm / LayerNorm 防止訊號在 forward/backward 擴散失控\n",
    "\n",
    "##### 2.5 控制逼近目標範圍（Rescaling）\n",
    "許多理論需要巨大權重，是因為要在整個 domain 上逼近非常大的函數。  \n",
    "實務上可：\n",
    "\n",
    "- 對目標函數 normalize  \n",
    "- 對輸入資料 rescale  \n",
    "\n",
    "降低需要的權重大小。\n",
    "\n",
    "##### 2.6 使用 Bayesian 方法\n",
    "以 prior 限制權重，使模型不會出現無限制的大參數。\n",
    "\n",
    "\\[\n",
    "p(\\theta\\mid \\text{data}) \\propto p(\\text{data}\\mid\\theta) p(\\theta)\n",
    "\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee3863c",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "#### (A) Function Approximation / Theory\n",
    "1. Mhaskar, H. N., & Poggio, T. (2016). *Deep vs. shallow networks*.  \n",
    "   — 說明深度網路可用更少的參數逼近複雜函數。\n",
    "\n",
    "2. Barron, A. (1993). *Universal Approximation Bounds for Superpositions of a Sigmoidal Function*.  \n",
    "   — 探討權重大小與逼近誤差的關係。\n",
    "\n",
    "3. Yarotsky, D. (2017). *Error bounds for approximations with ReLU networks*.  \n",
    "   — ReLU 神經網路的逼近效率及權重界限。\n",
    "\n",
    "4. Pinkus, A. (1999). *Approximation theory of the MLP model*.  \n",
    "   — 經典：討論多層感知機逼近的權重、深度與誤差。\n",
    "\n",
    "#### (B) Optimization & Generalization\n",
    "5. Goodfellow, Bengio, Courville — *Deep Learning* (Chapter 7, 8)  \n",
    "   — 討論大權重對訓練與泛化的影響。\n",
    "\n",
    "6. Neyshabur et al. (2015). *Norm-based capacity control*.  \n",
    "   — 權重的大小對 generalization 有直接關聯。\n",
    "\n",
    "7. Zhang et al. (2017). *Understanding deep learning requires rethinking generalization*.  \n",
    "   — 指出大權重模型可能記住雜訊並導致過擬合。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91211cb4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442b836a",
   "metadata": {},
   "source": [
    "## Week 4\n",
    "### Question\n",
    "When the number of categories is very large (e.g., tens of thousands of words in NLP), one-hot encoding produces extremely high-dimensional sparse vectors. This leads to inefficient memory usage and difficulties in capturing meaningful relationships between categories.  \n",
    "\n",
    "Or maybe in implementation, we usually don't use one-hot encoding?  \n",
    "\n",
    "當類別數量非常大時（例如 NLP 裡有成千上萬個單字），one-hot 編碼會產生極高維、且非常稀疏的向量。這會造成記憶體使用效率低落，也不容易捕捉類別之間有意義的關係。  \n",
    "\n",
    "或者，其實在實作中我們通常並不會真的用 one-hot 編碼？  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c59b25f",
   "metadata": {},
   "source": [
    "### Answer：實務上真的會用 one-hot 嗎？\n",
    "\n",
    "當類別數非常大（例如 NLP 裡的字詞字典有幾萬、幾十萬個詞）時，**理論上會用 one-hot 向量來表示類別，但實作中通常不會真的建立這個超高維稀疏向量**，原因包括：\n",
    "\n",
    "1. **記憶體與計算效率很差**  \n",
    "   - 真正的 one-hot 是長度為 `V`（字典大小）的向量，大部分都是 0，只有一個位置是 1。  \n",
    "   - 若 `V = 50,000` 或 `100,000`，每個樣本都存這麼長的向量非常浪費記憶體與計算量。\n",
    "\n",
    "2. **無法表示類別之間的語意關係**  \n",
    "   - 在 one-hot 表示中，每個類別之間的距離都一樣（例如 cos 距離、L2 距離），無法表達「dog 比 car 更接近 cat」這種結構。  \n",
    "   - 也就是說，**one-hot 只表示「是不是同一類」而不是「多像」或「語意多接近」。**\n",
    "\n",
    "3. **實務上常用的是「embedding lookup」，而不是explicit one-hot**  \n",
    "   - 在程式裡，我們通常把每個類別（例如單字）表示成一個整數 id，然後透過 **embedding matrix** 去查表拿到一個低維稠密向量。  \n",
    "   - 這個步驟在數學上等價於：  \n",
    "     先做 one-hot，再乘上 embedding matrix  \n",
    "     但實作時**不會真的把 one-hot 生出來**，而是直接用 index 查表，節省很多計算。\n",
    "   - PyTorch 的 `nn.Embedding`、TensorFlow/Keras 的 `Embedding` layer 就是這種典型做法。\n",
    "\n",
    "4. **embedding 還可以透過訓練學到語意結構**  \n",
    "   - 如 word2vec、GloVe、fastText 等方法，會讓「語意接近的詞」在 embedding 空間中距離也比較近，這是 one-hot 完全做不到的。\n",
    "\n",
    "**所以總結：**\n",
    "\n",
    "- 理論上可以把類別想成 one-hot；  \n",
    "- 但**實務上幾乎不會顯式建立 one-hot 向量**，而是：  \n",
    "  - 用「整數 id」＋「embedding lookup」來實現，  \n",
    "  - 得到維度較低、可訓練、能表示語意關係的向量。\n",
    "  \n",
    "\n",
    "### References\n",
    "\n",
    "1. Ian Goodfellow, Yoshua Bengio, Aaron Courville,  \n",
    "   *Deep Learning*, MIT Press, Chapter 12 (Distributed Representations and Language Models).  \n",
    "   - 討論為何要用分佈式表示（embeddings）而不是 one-hot，特別是在語言模型中的動機。\n",
    "\n",
    "2. Tianqi Chen and Mu Li,  \n",
    "   *Introduction to Word Embedding*, in *Dive into Deep Learning* (D2L), NLP chapters.  \n",
    "   - 說明從 one-hot 到 embedding 的轉換，並展示實作上如何用 embedding 矩陣代替 one-hot。\n",
    "\n",
    "3. Tomas Mikolov et al.,  \n",
    "   *Efficient Estimation of Word Representations in Vector Space* (word2vec).  \n",
    "   - 經典論文，展示如何學習 word embeddings，動機之一就是避免高維 one-hot 表示的缺點。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d15d2c8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566651ea",
   "metadata": {},
   "source": [
    "## Week 5\n",
    "### Question\n",
    "We observe i.i.d. samples $(x_i, \\tilde y_i)$, where the true label  \n",
    "$y \\in \\{0,1\\}$ is flipped by an **unknown** noise/confusion matrix $T$.  \n",
    "The generative model is:\n",
    "\n",
    "$$\n",
    "y \\sim \\text{Bern}(\\pi), \\qquad x \\mid y=k \\sim \\mathcal N(\\mu_k, \\Sigma_k),\n",
    "$$\n",
    "$$\n",
    "\\Pr(\\tilde y=j \\mid y=k) = T_{jk}.\n",
    "$$\n",
    "\n",
    "Thus the observed likelihood is:\n",
    "\n",
    "$$\n",
    "p(x, \\tilde y = j)\n",
    "  = \\pi_0 T_{j0}\\, \\mathcal N_0(x)\n",
    "  + \\pi_1 T_{j1}\\, \\mathcal N_1(x).\n",
    "$$\n",
    "\n",
    "**Question:**  \n",
    "From only $p(x, \\tilde y)$, are the parameters  \n",
    "$\\{\\pi, \\mu_0, \\mu_1, \\Sigma_0, \\Sigma_1\\}$ and the unknown $T$  \n",
    "**identifiable up to label swapping**?  \n",
    "If not, what are the *minimal assumptions* needed for identifiability  \n",
    "(e.g., invertible $T$, distinct Gaussian components, or small side information)?\n",
    "\n",
    "\n",
    "我們觀察到 i.i.d. 的資料 $(x_i, \\tilde y_i)$，其中真實標籤  \n",
    "$y \\in \\{0,1\\}$ 會被未知的雜訊矩陣 $T$ 翻轉。模型為：\n",
    "\n",
    "$$\n",
    "y \\sim \\text{Bern}(\\pi),\\qquad x \\mid y=k \\sim \\mathcal N(\\mu_k, \\Sigma_k),\n",
    "$$\n",
    "$$\n",
    "\\Pr(\\tilde y=j \\mid y=k) = T_{jk}.\n",
    "$$\n",
    "\n",
    "因此我們看到的分佈是：兩個 Gaussian component 相同、但混合權重未知的 mixture。\n",
    "\n",
    "**問題：**  \n",
    "僅從 $p(x, \\tilde y)$ 能不能唯一決定  \n",
    "$\\{\\pi, \\mu_0, \\mu_1, \\Sigma_0, \\Sigma_1\\}$ 和未知的 $T$？  \n",
    "如果不能，則能做到需要的最弱的條件是甚麼？例如：\n",
    "\n",
    "- 雜訊矩陣 $T$ 可逆、對角優勢  \n",
    "- 兩個 Gaussian component 不相同  \n",
    "- 或需要少量乾淨資料、已知先驗、或雜訊率界限等額外資訊。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ac5202",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "要讓 $\\{ \\pi,\\mu_0,\\mu_1,\\Sigma_0,\\Sigma_1 \\}$ 與未知的雜訊矩陣 $T$  \n",
    "能從 $p(x,\\tilde y)$ 中被唯一（最多差 label swap）識別，需要以下最小條件：\n",
    "\n",
    "\n",
    "##### **1. Gaussian 組件必須不同（Distinct Components）**\n",
    "若兩個 component 完全相同：\n",
    "$$\n",
    "(\\mu_0,\\Sigma_0) = (\\mu_1,\\Sigma_1),\n",
    "$$\n",
    "那無論 $T$ 是什麼，觀察到的分佈都會一樣，完全無法分辨類別。\n",
    "\n",
    "**最小條件：**\n",
    "$$\n",
    "\\mathcal N(\\mu_0,\\Sigma_0) \\neq \\mathcal N(\\mu_1,\\Sigma_1).\n",
    "$$\n",
    "\n",
    "##### **2. 雜訊矩陣 $T$ 必須可逆（Invertible）**\n",
    "若 $T$ 不可逆（例如兩行相同），則不同的 $(\\pi,\\mu_k,\\Sigma_k)$  \n",
    "可以透過不同的 $T$ 得到同樣的 $p(x,\\tilde y)$，無法唯一辨識。\n",
    "\n",
    "**最小條件：**\n",
    "$$\n",
    "\\det(T) \\neq 0.\n",
    "$$\n",
    "\n",
    "##### **3. 雜訊不能太大（Diagonal Dominance）**\n",
    "若 $T$ 幾乎完全把 0 變 1、1 變 0（或接近全亂數），  \n",
    "那 $(\\pi, T)$ 的組合會高度不識別。\n",
    "\n",
    "通常需要：\n",
    "$$\n",
    "T_{00}, T_{11} > \\tfrac{1}{2}.\n",
    "$$\n",
    "\n",
    "這確保「看到的標籤」還保留部分真實訊息。\n",
    "\n",
    "##### **4. 兩個 mixture（對不同 $\\tilde y$）的 mixing weight 足夠不同**\n",
    "對每個 observed label $j$：\n",
    "$$\n",
    "p(x \\mid \\tilde y=j) = c_{j0} \\mathcal N_0(x) + c_{j1} \\mathcal N_1(x)\n",
    "$$\n",
    "\n",
    "兩個 mixture 必須提供足夠的線性獨立資訊來解回：\n",
    "- component 分布 (Gaussian 參數)\n",
    "- mixing weight（含 $\\pi$ 與 $T$）\n",
    "\n",
    "這在 $T$ 可逆時成立。\n",
    "\n",
    "\n",
    "\n",
    "### References\n",
    "\n",
    "#### **(A) Mixture Model Identifiability**\n",
    "1. Teicher, H. (1963). *Identifiability of finite mixtures.*  \n",
    "   — 經典定理：Gaussian mixtures 在組件不同時是可識別的。\n",
    "\n",
    "2. Yakowitz & Spragins (1968). *On the identifiability of mixtures.*  \n",
    "   — 多種 mixture 模型的可識別性條件。\n",
    "\n",
    "3. Allman, Matias, Rhodes (2009). *Identifiability of latent structure models with many observed variables.*  \n",
    "   — 混合模型 + 隱變數的可識別性，技術上最強。\n",
    "\n",
    "\n",
    "#### **(B) Label Noise / Confusion Matrix Identifiability**\n",
    "4. Scott, C. (2015). *A Rate of Convergence for Mixture Proportion Estimation.*  \n",
    "   — 介紹類別雜訊矩陣的可識別條件。\n",
    "\n",
    "5. Natarajan et al. (2013). *Learning with Noisy Labels.*  \n",
    "   — 使用可逆的 noise matrix 來校正 loss 的基礎模型。\n",
    "\n",
    "6. Patrini et al. (2017). *Making Deep Neural Networks Robust to Label Noise.*  \n",
    "   — 討論 confusion matrix 可識別性與 invertibility 的必要性。\n",
    "\n",
    "#### **(C) Gaussian Discriminant Analysis with Label Noise**\n",
    "7. Frénay & Verleysen (2014). *Classification in the presence of label noise.*  \n",
    "   — 對 binary noise model 的 identifiability 有完整整理。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4a9e5d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb80243",
   "metadata": {},
   "source": [
    "## Week 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fca0c8c",
   "metadata": {},
   "source": [
    "### Question\n",
    "When ChatGPT generates machine learning code, are all neural network structures the same? What is the underlying mechanism behind it?\n",
    "\n",
    "每次請chatgpt生成機器學習的code的時候他們的神經網路架構都會一樣嗎？背後的機制是甚麼？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d3247c",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "#### 1：為什麼 ChatGPT 產生的神經網路程式碼常常長得很像？\n",
    "\n",
    "1. **使用最常見、最穩定的網路模板**  \n",
    "   ChatGPT 會優先生成最不容易出錯、最常見的 baseline，例如：\n",
    "   - MLP（多層感知機）\n",
    "   - CNN 標準卷積區塊\n",
    "   - Transformer encoder block\n",
    "   - U-Net（在 diffusion 任務中）\n",
    "   這些結構在各類任務中都「安全又好用」，所以看起來很像。\n",
    "\n",
    "2. **根據任務自動填入典型架構**  \n",
    "   例如：\n",
    "   - 分類 → 給 MLP/CNN  \n",
    "   - NLP → 給 Transformer/RNN  \n",
    "   - Diffusion → 給 U-Net 或 MLP + time embedding  \n",
    "   - Score matching → MLP + skip + σ embedding  \n",
    "   ChatGPT 會根據你的 prompt 推論一個最常見的 baseline。\n",
    "\n",
    "3. **不會主動「發明新架構」**  \n",
    "   除非你要求，否則模型會沿用社群中最常使用的模式，避免產生怪異或錯誤的程式碼。\n",
    "\n",
    "#### 2：ChatGPT 實際上是如何產生神經網路程式碼的？\n",
    "\n",
    "底層不是模板，也不是規則引擎，而是：\n",
    "\n",
    " **基於大型語言模型的「樣式抽樣 (pattern sampling)」**\n",
    "\n",
    "ChatGPT 的運作方式包含：\n",
    "\n",
    "1. **解析你的需求（語意理解）**  \n",
    "根據你的 prompt 推論你想做的任務，例如：  \n",
    "「build a diffusion model」 → 預期要有 time embedding、noise schedule、U-Net 或 MLP。\n",
    "2. **從訓練語料中學習常見的程式架構**  \n",
    "訓練時吸收了大量人類寫的神經網路程式碼，包括：\n",
    "- PyTorch 官方程式碼\n",
    "- HuggingFace models\n",
    "- Kaggle / GitHub 專案\n",
    "- 教科書與 blog（如 Karpathy, Lilian Weng）\n",
    "\n",
    "因此模型內部有「常見 NN 程式碼的統計分佈」。\n",
    "\n",
    "3. **從這些分佈中抽樣出最有可能的正確回答**  \n",
    "這不是複製，而是：\n",
    "> 「從人類最常寫的結構中，抽樣出一個最合理的版本。」\n",
    "\n",
    "\n",
    "### References\n",
    "\n",
    "1. Radford, A., Wu, J., Child, R., et al. (2019).  \n",
    "   **Language Models are Unsupervised Multitask Learners.**  \n",
    "   (GPT-2 technical report)\n",
    "\n",
    "2. Kaplan, J., McCandlish, S., Henighan, T., et al. (2020).  \n",
    "   **Scaling Laws for Neural Language Models.**\n",
    "\n",
    "3. Chen, M., Tworek, J., Jun, H., et al. (2021).  \n",
    "   **Evaluating Large Language Models Trained on Code.**  \n",
    "   (Codex)\n",
    "\n",
    "4. Olsson, C., et al. (2022).  \n",
    "   **In-context Learning and Induction Heads.**  \n",
    "   (Anthropic)\n",
    "\n",
    "5. Nanda, N., et al. (2023).  \n",
    "   **Emergent Linear Representations in Language Models.**\n",
    "\n",
    "6. Wei, J., Tay, Y., et al. (2022).  \n",
    "   **Emergent Abilities of Large Language Models.**\n",
    "\n",
    "7. Li, Y., et al. (2023).  \n",
    "   **Neural Architecture Search with Large Language Models.**\n",
    "\n",
    "8. Svyatkovskiy, A., et al. (2020).  \n",
    "   **Pythia: A Code Completion Model.**\n",
    "\n",
    "9. Allamanis, M. (2018).  \n",
    "   **A Survey of Machine Learning for Big Code.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af8b083",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c005c2e",
   "metadata": {},
   "source": [
    "## Week 7\n",
    "### Question\n",
    "What are the theoretical limitations of denoising score matching, when the noise level $\\sigma $ becomes very small or very large?  \n",
    "\n",
    "當$\\sigma$很大或很小的時候會對DSM有什麼理論上的限制?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8989a23",
   "metadata": {},
   "source": [
    "### Anawer\n",
    "\n",
    "#### 一、當噪音非常小：σ → 0\n",
    "\n",
    "##### 1. Loss 會變得非常不穩定  \n",
    "DSM 的 loss 含有項目：\n",
    "$$\n",
    "\\frac{\\epsilon}{\\sigma}\n",
    "$$\n",
    "\n",
    "$σ$ 越小，這項越大，導致：\n",
    "- 梯度爆炸  \n",
    "- 訓練震盪、不收斂  \n",
    "- 數值條件變得極差（ill-conditioned）\n",
    "\n",
    "##### 2. 模型只會學到「資料附近很局部的 score」  \n",
    "噪音太小 → $x + σϵ$ 幾乎就是資料本身  \n",
    "→ 模型只看到 data manifold 附近的梯度  \n",
    "→ 完全學不到整體分佈的形狀（global structure）\n",
    "\n",
    "這會讓 diffusion 的反向過程失效。\n",
    "\n",
    "##### 3. 真實的 score 在資料邊界可能不可微  \n",
    "高維資料（圖像等）通常落在低維 manifold 上，  \n",
    "在 σ → 0 時 DSM 其實在逼近：\n",
    "$$\n",
    "\\nabla_x \\log p_\\text{data}(x)\n",
    "$$\n",
    "但這個在數學上可能 **不存在或不連續**。  \n",
    "→ 問題變成 ill-posed。\n",
    "\n",
    "\n",
    "#### 二、當噪音非常大：σ → ∞\n",
    "\n",
    "##### 1. 模型看到的資料變成「純高斯噪音」  \n",
    "$x + σϵ$ 幾乎完全是 noise，資料的結構被淹沒。  \n",
    "此時 score 接近：\n",
    "$$\n",
    "s(x) \\approx -\\frac{x}{\\sigma^2}\n",
    "$$\n",
    "即高斯分佈自己的梯度，與資料無關。\n",
    "\n",
    "→ 模型學不到任何 data manifold 的形狀。\n",
    "\n",
    "##### 2. Loss 的梯度訊號非常弱  \n",
    "大 $σ$ 時：\n",
    "- 梯度趨近 $0$  \n",
    "- 模型更新非常慢  \n",
    "- 甚至出現 collapse（全部輸出為 0）\n",
    "\n",
    "##### 3. 多噪音訓練時，大 σ 的樣本會干擾其他噪音層  \n",
    "如果以不同 $σ$ 混合訓練 DSM：  \n",
    "$σ$ 很大的 sample 會「主導」梯度，  \n",
    "導致模型朝著錯誤方向收斂。\n",
    "\n",
    "### References\n",
    "\n",
    "1. **Pascal Vincent (2011).  \n",
    "   “A Connection Between Score Matching and Denoising Autoencoders.”**  \n",
    "   - 最早正式提出 DSM 理論。  \n",
    "   - 討論噪音尺度 σ 對 score matching 的性質影響（尤其 σ → 0 會導致不穩定）。\n",
    "\n",
    "2. **Yang Song & Stefano Ermon (2019).  \n",
    "   “Generative Modeling by Estimating Gradients of the Data Distribution.” (NIPS)**  \n",
    "   - Score-based models經典論文。  \n",
    "   - 直接描述 small-noise DSM 的 instability，以及 DSM 只能在局部近似 score 的限制。\n",
    "\n",
    "3. **Yang Song et al. (2020).  \n",
    "   “Improved Techniques for Training Score-Based Generative Models.”**  \n",
    "   - 明確說明：  \n",
    "     - σ 太小 → DSM loss ill-conditioned  \n",
    "     - σ 太大 → 梯度訊號消失  \n",
    "   - 提出多 σ（noise schedule）來避免上述問題。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6752a99b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb2b6b3",
   "metadata": {},
   "source": [
    "## Week 8\n",
    "### Question\n",
    "Why does taking the expectation over random directions $v$ in sliced score matching approximate the original score matching objective?\n",
    "\n",
    "為什麼對隨機方向取 expectation value 可以近似原始 Score Matching？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293a7458",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "原始 Score Matching 的目標是**Score Matching 需要最小化**：\n",
    "$$\n",
    "\\mathbb{E}_{p(x)}\\left[\\|\\nabla_x \\log p_\\theta(x)-\\nabla_x \\log p(x)\\|_2^2\\right].\n",
    "$$\n",
    "\n",
    "裡面的 L2 norm 可以拆成：\n",
    "$$\n",
    "\\|\\Delta(x)\\|_2^2=\\sum_{i=1}^d \\Delta_i(x)^2,\n",
    "$$\n",
    "其中 $\\Delta(x)$ 是 score difference。\n",
    "\n",
    "#### 關鍵性質：隨機方向投影可以恢復 L2 norm\n",
    "取一個隨機方向 $v \\sim \\text{Unif}(\\mathbb{S}^{d-1})$，則：\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_v[(v^\\top \\Delta)^2]\n",
    "= \\frac{1}{d} \\|\\Delta\\|_2^2.\n",
    "$$\n",
    "\n",
    "理由：\n",
    "$$\n",
    "\\mathbb{E}_v[vv^\\top] = \\frac{1}{d} I_d,\n",
    "$$\n",
    "因此：\n",
    "$$\n",
    "\\mathbb{E}_v[(v^\\top \\Delta)^2]\n",
    "= \\Delta^\\top \\mathbb{E}_v[vv^\\top] \\Delta\n",
    "= \\Delta^\\top \\left(\\frac{1}{d}I_d\\right)\\Delta\n",
    "= \\frac{1}{d}\\|\\Delta\\|_2^2.\n",
    "$$\n",
    "\n",
    "\n",
    "#### 結論：隨機方向的投影能重建完整的 Score Matching loss\n",
    "\n",
    "因此原始 Score Matching 可改寫成：\n",
    "\n",
    "$$\n",
    "\\mathcal{J}(\\theta)\n",
    "\\propto \n",
    "\\mathbb{E}_{x \\sim p}\\,\\mathbb{E}_{v \\sim \\text{Unif}}\n",
    "\\left[(v^\\top(\\nabla \\log p_\\theta(x) - \\nabla\\log p(x)))^2\\right].\n",
    "$$\n",
    "\n",
    "也就是說：\n",
    "\n",
    "> **只用隨機方向的投影平方誤差（再取期望），就能等價地近似原始的 score matching 目標。**\n",
    "\n",
    "#### 這樣做的好處\n",
    "- 不需要計算 Hessian 或 divergence  \n",
    "- 僅需一次 backward 就能求方向導數  \n",
    "- 在高維時，只用少量方向就能很好地近似原本的 L2 norm  \n",
    "- 計算成本遠低於原版 Score Matching\n",
    "\n",
    "### References\n",
    "1. **Song, Yang & Ermon, Stefano. (2020).  \n",
    "   “Sliced Score Matching: A Scalable Approach to Density and Score Estimation.” (ICLR)**  \n",
    "   - 這篇是 SSM 的原始論文。  \n",
    "   - 文中直接推導：  \n",
    "     $$\n",
    "     \\mathbb{E}_{v\\sim \\text{Unif}}[(v^\\top \\Delta)^2] = \\frac{1}{d}\\|\\Delta\\|^2\n",
    "     $$\n",
    "     因此可以用隨機方向近似完整的 score matching loss。  \n",
    "\n",
    "2. **Hyvärinen, Aapo. (2005).  \n",
    "   “Estimation of Non-Normalized Statistical Models by Score Matching.”**  \n",
    "   - Score Matching 的基礎理論來源。  \n",
    "   - SSM 的推導建立在原始 SM 的 L2 形式，因此要引用這篇。\n",
    "\n",
    "3. **Vincent, Pascal. (2011).  \n",
    "   “A Connection Between Score Matching and Denoising Autoencoders.”**  \n",
    "   - 提到向量 score 的 L2 結構與投影的關係，  \n",
    "     支撐了 SSM 中「用投影近似真實 gradient difference」的觀念。\n",
    "\n",
    "4. **J. M. M. Montanari et al. (2022).  \n",
    "   “On the Geometry of Score Matching.”**  \n",
    "   - 討論 score matching 的幾何性質，特別是 L2 norm 與 isotropic projection 的等價性。  \n",
    "   - 與 SSM 的方向平均原理高度相關。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c11c692",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
